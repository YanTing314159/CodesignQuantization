{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"main.ipynb","provenance":[],"mount_file_id":"1-2E5V-22846jA6vWmum3D6i13bA5mzcW","authorship_tag":"ABX9TyM2SsiSVwrGcCknJDJ+XILJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"J27lYW1Qqfen"},"source":["%cd /content/drive/MyDrive/src/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FIFVmclv5i74"},"source":["#!tar zxvf cifar100.tar.gz"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6SZw-g_gWWkO","executionInfo":{"status":"ok","timestamp":1630857318056,"user_tz":-480,"elapsed":223837,"user":{"displayName":"葉彥廷","photoUrl":"","userId":"08964691184728056359"}},"outputId":"afbe1693-2b32-43aa-c0ae-829452b73be2"},"source":["!python test.py"],"execution_count":125,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/torch/quantization/observer.py:124: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n","  reduce_range will be deprecated in a future release of PyTorch.\"\n","processing:0/79\n","acc:0.7212, evaluate time:220.634626 sec\n"]}]},{"cell_type":"code","metadata":{"id":"CHwgE7c9y4UI"},"source":["!python static_quantize.py"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NREhSZyKYWBd"},"source":["!python QAT.py"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GLndxOoViWE_"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jLS6uqosiWLG"},"source":["import torch\n","\n","state_dict1 = torch.load(\"../pth/resnet56_tuned20.pth\")\n","state_dict2 = torch.load(\"../pth/resnet56_quantized20.pth\")\n","state_dict3 = torch.load(\"./test.pth\")\n","\n","\"\"\"\n","print(type(state_dict1))\n","i = 1\n","for k in state_dict1:\n","  print(f\"key {i}: {k}\")\n","  print(type(state_dict1[k]), state_dict1[k].size())\n","  print(state_dict1[k][0])\n","  i += 1\n","  if i >= 2:\n","    break\n","\"\"\"\n","\n","print(type(state_dict2))\n","i = 1\n","for k in state_dict2:\n","  print(f\"key {i}: {k}\")\n","  print(type(state_dict2[k]))\n","  print(state_dict2[k])\n","  i += 1\n","  if i >= 2:\n","    break\n","\n","print(type(state_dict3))\n","i = 1\n","for k in state_dict3:\n","  print(f\"key {i}: {k}\")\n","  print(type(state_dict3[k]))\n","  print(state_dict3[k])\n","  i += 1\n","  if i >= 2:\n","    break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wpck3lu1T20M"},"source":["import torch\n","import torch.nn as nn\n","\n","def print_key(model, num=5):\n","  _ = 0\n","  keys = []\n","  for k in model.state_dict():\n","    keys.append(f\"key{_+1}: \" + k)\n","    _ += 1\n","    if _ >= num:\n","      break\n","  print(keys)\n","\n","class test(nn.Module):\n","  def __init__(self):\n","    super(test, self).__init__()\n","    self.lin1 = nn.Linear(10, 5)\n","    self.act1 = nn.ReLU()\n","    self.lin2 = nn.Linear(5, 3)\n","\n","    self.quant = torch.quantization.QuantStub()\n","    self.dequant = torch.quantization.DeQuantStub()\n","\n","  def forward(self, x):\n","    x = self.quant(x)\n","    x = self.lin1(x)\n","    x = self.act1(x)\n","    x = self.lin2(x)\n","    x = self.dequant(x)\n","    return x\n","\n","m = test()\n","m.qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')\n","torch.quantization.prepare_qat(m, inplace=True)\n","torch.quantization.convert(m.eval(), inplace=True)\n","torch.save(m.state_dict(), \"./test1.pth\")\n","torch.save(m, \"./test1.mod\")\n","\n","print(\"m\")\n","print(m)\n","print(m.state_dict())\n","\n","m2 = torch.load(\"./test1.mod\")\n","print(\"m2\")\n","print(m2)\n","print(m2.state_dict())\n"],"execution_count":null,"outputs":[]}]}